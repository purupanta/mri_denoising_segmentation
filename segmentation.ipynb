{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1nD-0hxPp7Z_MGjzYX87YFdoE59keQgYw","authorship_tag":"ABX9TyPuJnH46VAzKLsDZPSRQojY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**BASIC METHODOLOGY:**\n","\n","Tool used: Google Collab, Google Drive to store the MRI Image file\n","Program used: Python, and libraries: mumpy, os, cv2, matplotlib, skimage\n","\n","Input: The google collab mounts the google drive in its environment and reads the input file (Code shown below)\n","\n","The algorithm basically covers some of the pre-processing (converting to grayscale) of the given MRI Image. Then it performs the threshold-segmentation."],"metadata":{"id":"Ssd5v1zDo6WK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRXRsHL45Mnp"},"outputs":[],"source":["# Importing the namespace libraries\n","\n","%matplotlib inline\n","import os\n","import numpy as np\n","import cv2\n","from matplotlib import pyplot as plt\n","from skimage.morphology import extrema\n","from skimage.segmentation import watershed as skwater\n","\n","# I have put my image files in google drive. So mounting the google drive in my Google Collab environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Just testing to see the current directory location.\n","print(os.getcwd())"]},{"cell_type":"code","source":["# a function is defined to plot the images and compare the resulting segmentation\n","\n","def PlotMyImage(image_title,img,ctype):\n","  plt.figure(figsize=(5, 5))\n","  # Plot the image based on its type\n","  if ctype=='bgr':\n","    # get blue, green, red\n","    b,g,r = cv2.split(img)\n","    # switch it to rgb\n","    rgb_img = cv2.merge([r,g,b])\n","    plt.imshow(rgb_img)\n","  elif ctype=='hsv':\n","    rgb = cv2.cvtColor(img,cv2.COLOR_HSV2RGB)\n","    plt.imshow(rgb)\n","  elif ctype=='gray':\n","    plt.imshow(img,cmap='gray')\n","  elif ctype=='rgb':\n","    plt.imshow(img)\n","  else:\n","    raise Exception(\"Unknown colour type\")\n","\n","  # Printing the x-axis and y-axis scales\n","  plt.axis('on')\n","  # Printing the title of the image\n","  plt.title(image_title)\n","  plt.show()"],"metadata":{"id":"hoUQ8lA-OMlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6aeMFi_6IX-"},"outputs":[],"source":["#Read in the original image file from the google drive\n","orig_img = cv2.imread('./drive/MyDrive/Colab Notebooks/BMI734/hw1/mri_brain.jpg')\n","\n","# Converting an image from one color space to another: RGB Color to Grayscale\n","gray_orig_img = cv2.cvtColor(orig_img,cv2.COLOR_BGR2GRAY)\n","PlotMyImage('Original Image - Brain with Skull',gray_orig_img,'gray')\n","print(\"\\n\\n\");\n"]},{"cell_type":"code","source":["# We are plotting a histogram of the intensities in the grayscale image\n","# The data seems to be BiModal - distribution which means two clearly separate groups are visible in the histogram we plotted below\n","print(\"\\n\\n\")\n","plt.hist(gray_orig_img.ravel(),256)\n","plt.show()"],"metadata":{"id":"4Y1WxAb5SBRI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OTSU's Threshold (Ref. https://en.wikipedia.org/wiki/Otsu%27s_method) is now been implemented.\n","# It basically returns a single intensity threshold that separates pixels into two classes (foreground and background)\n","# The algorithm determines the tresholds by minimizing intra-class intensity variabce  (Such as by using the euclidian distance)\n","ret, thresh = cv2.threshold(gray_orig_img,0,255,cv2.THRESH_OTSU)\n","PlotMyImage('Applying Otsu',thresh,'gray')"],"metadata":{"id":"1XPXz-ib_Pq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["colormask = np.zeros(orig_img.shape, dtype=np.uint8)\n","colormask[thresh!=0] = np.array((0,0,255))\n","blended = cv2.addWeighted(orig_img,0.7,colormask,0.1,0)\n","PlotMyImage('Blended', blended, 'bgr')"],"metadata":{"id":"z2iM14ij_bC6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ret, markers = cv2.connectedComponents(thresh)\n","\n","print(np.max(markers))\n","\n","#Get the area taken by each component. Ignore label 0 since this is the background.\n","marker_area = [np.sum(markers==m) for m in range(np.max(markers)) if m!=0]\n","\n","# The largest component by area\n","# We dropped zero above, so we add 1 here\n","largest_component = np.argmax(marker_area) + 1\n","\n","# Now we extract pixels which correspond to the brain. (Note: Brain is the largest component)\n","brain_mask = markers==largest_component\n","\n","\n","# Make a copy of the original image\n","brain_out = orig_img.copy()\n","\n","# In the copy of the original image we just created above,\n","# we are going to clear those pixels that don't correspond to the brain\n","brain_out[brain_mask==False] = (0,0,0)\n","\n","# Now plot the image of brain only\n","PlotMyImage('Removed the Brain Cover skull - isolated the brain', brain_out,'rgb')"],"metadata":{"id":"8fApUw_T_ih7"},"execution_count":null,"outputs":[]}]}